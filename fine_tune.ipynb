{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas transformers datasets evaluate accelerate torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "CSV_FILE_PATH = '/Users/himanshusharma/Personal_Code/FineTune/data/News_Category.csv'\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "OUTPUT_MODEL_DIR = '/Users/himanshusharma/Personal_Code/FineTune/news_classifier_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load and Preprocess Data ---\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Combine headline and short description\n",
    "    df['text'] = df['headline'] + \" \" + df['short_description']\n",
    "\n",
    "    # Drop irrelevant columns for training\n",
    "    df = df[['text', 'category']]\n",
    "    df.dropna(subset=['category', 'text'], inplace=True)\n",
    "\n",
    "    # Map categories to unique integer IDs\n",
    "    unique_categories = df['category'].unique().tolist()\n",
    "    category_to_id = {cat: i for i, cat in enumerate(unique_categories)}\n",
    "    id_to_category = {i: cat for i, cat in enumerate(unique_categories)}\n",
    "    df['label'] = df['category'].map(category_to_id)\n",
    "\n",
    "    # Split data into train and test sets (stratified for balanced categories)\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, stratify=df['category'], random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert Pandas DataFrames to Hugging Face Dataset format\n",
    "    train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "    test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
    "\n",
    "    return train_dataset, test_dataset, id_to_category, category_to_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c45e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Tokenize Data ---\n",
    "def tokenize_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    # The 'truncation=True' handles long descriptions, 'padding=True' dynamically pads to max length\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. Train the Model ---\n",
    "def train_model(train_dataset, test_dataset, id_to_category):\n",
    "    # Load pre-trained model with a classification head\n",
    "    num_labels = len(id_to_category)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, num_labels=num_labels\n",
    "    ).to(device)\n",
    "\n",
    "    # Tokenize the datasets\n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Define evaluation metrics\n",
    "    metric = evaluate.load(\"f1\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        # Using 'macro' F1 score to treat all categories equally\n",
    "        return metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "\n",
    "    # Define training arguments (hyperparameters)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_MODEL_DIR,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "    )\n",
    "\n",
    "    # Initialize the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the final model\n",
    "    trainer.save_model(OUTPUT_MODEL_DIR)\n",
    "    print(f\"Model saved to {OUTPUT_MODEL_DIR}\")\n",
    "\n",
    "    return model, trainer, id_to_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Use the Model for Prediction ---\n",
    "def predict_category(text_to_predict, saved_model_path, id_to_category_map):\n",
    "    # Load the tokenizer and model from the saved directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(saved_model_path).to(device)\n",
    "\n",
    "    # Preprocess the input text\n",
    "    inputs = tokenizer(text_to_predict, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted label index and convert it back to the category name\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    predicted_category = id_to_category_map[prediction]\n",
    "\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Load and prepare data\n",
    "train_ds, test_ds, id_to_cat, cat_to_id = load_and_preprocess_data(CSV_FILE_PATH)\n",
    "print(f\"Loaded data with {id_to_cat} unique categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c73f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Train and save the model\n",
    "# Note: GPU reqd.\n",
    "trained_model, trainer, id_to_cat_map = train_model(train_ds, test_ds, id_to_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Test with a new headline/description\n",
    "new_text = \"Scientists discover new black hole in nearby galaxy, challenging existing theories about cosmic formation.\"\n",
    "predicted_category = predict_category(new_text, OUTPUT_MODEL_DIR, id_to_cat)\n",
    "\n",
    "print(f\"\\nText: '{new_text}'\")\n",
    "print(f\"Predicted Category: {predicted_category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
